---
title: "KNN with R"
author: "Umakanth Prakash"
output: pdf_document
---

```{r}
library(caret)
library(ggplot2)
library(plotly)


iris <- read.csv('iris.csv')

print(head(iris))
print(unique(iris$Species))


iris_filtered <- iris[iris$Species %in% c("virginica", "versicolor"), ]

X <- iris_filtered[, 1:4]
y <- iris_filtered$Species

# Lets split the data into training and testing sets
set.seed(1)
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[train_index, ]
X_test <- X[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]

k_values <- 1:30

accuracies <- c()

# doing cross validation for each k
for (k in k_values) {
  # Here we are training the model
  knn_model <- knn3Train(X_train, X_test, y_train, k = k)
  
  # and we will calculate the accuracy
  accuracy <- mean(knn_model == y_test)
  accuracies <- c(accuracies, accuracy)
}

# Now we will plot the accuracy vs k values
plot_data <- data.frame(
  k = k_values,
  Accuracy = accuracies
)

plot <- ggplot(plot_data, aes(x = k, y = Accuracy)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  labs(title = "Accuracy vs. k Value (Euclidean Distance)", x = "k", y = "Accuracy") +
  theme_minimal()

# using plotly for interactive plot
interactive_plot <- ggplotly(plot)

interactive_plot

# We will use the k value 5 to train the model
best_k <- 5
final_knn_model <- knn3Train(X_train, X_test, y_train, k = best_k)

# lets make prediction on our test set
y_pred <- final_knn_model

y_pred <- factor(y_pred, levels = levels(y_test))

# generating the confusion matrix
conf_matrix <- table(Predicted = y_pred, Actual = y_test)
print("Confusion Matrix:")
print(conf_matrix)

# calculating the accuracy once again
accuracy <- mean(y_pred == y_test)
print(paste("Accuracy with k =", best_k, ":", accuracy))


```


